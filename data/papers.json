[
  {
    "title": "Kitaev-derived Gapless Spin Liquid in the $K$-$J$-$\u0393$-$\u0393'$ Quantum Magnet Na$_2$Co$_2$TeO$_6$",
    "summary": "The realization of quantum spin liquids (QSLs) in Kitaev magnets represents\nan intriguing topic in frustrated quantum magnetism. Despite prediction in the\npure Kitaev honeycomb model, realization of QSLs in realistic systems and\nmaterials remain scarce. The recent discovery of cobalt-based compound\nNa$_2$Co$_2$TeO$_6$ has raised significant research interest. By establishing a\nrealistic $K$-$J$-$\\Gamma$-$\\Gamma'$ model for Na$_2$Co$_2$TeO$_6$ -- with a\ndominant antiferromagnetic (AFM) Kitaev interaction ($K>0$) that quantitatively\nexplains its thermodynamics measurements -- we reveal an intermediate gapless\nQSL phase under [111] magnetic fields with tensor-network calculations. We\nconfirm the QSL nature of this phase by demonstrating its adiabatic connection\nto the intensively studied intermediate QSL of the pure AFM Kitaev model under\nout-of-plane fields. Our results show excellent agreement with recent\nhigh-field experiments, thereby explaining the intermediate-field phase in\nNa$_2$Co$_2$TeO$_6$. These findings bridge the gap between theoretical\nproposals for a Kitaev-derived QSL and experimental realization, opening new\navenues for exploring exotic quantum states of matter in realistic Kitaev\nmaterials.",
    "authors": [
      "Han Li",
      "Xu-Guang Zhou",
      "Gang Su",
      "Wei Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2509.08821v1"
  },
  {
    "title": "QCardEst/QCardCorr: Quantum Cardinality Estimation and Correction",
    "summary": "Cardinality estimation is an important part of query optimization in DBMS. We\ndevelop a Quantum Cardinality Estimation (QCardEst) approach using Quantum\nMachine Learning with a Hybrid Quantum-Classical Network. We define a compact\nencoding for turning SQL queries into a quantum state, which requires only\nqubits equal to the number of tables in the query. This allows the processing\nof a complete query with a single variational quantum circuit (VQC) on current\nhardware. In addition, we compare multiple classical post-processing layers to\nturn the probability vector output of VQC into a cardinality value. We\nintroduce Quantum Cardinality Correction QCardCorr, which improves classical\ncardinality estimators by multiplying the output with a factor generated by a\nVQC to improve the cardinality estimation. With QCardCorr, we have an\nimprovement over the standard PostgreSQL optimizer of 6.37 times for JOB-light\nand 8.66 times for STATS. For JOB-light we even outperform MSCN by a factor of\n3.47.",
    "authors": [
      "Tobias Winker",
      "Jinghua Groppe",
      "Sven Groppe"
    ],
    "pdf_url": "http://arxiv.org/pdf/2509.08817v1"
  },
  {
    "title": "Scaling Truth: The Confidence Paradox in AI Fact-Checking",
    "summary": "The rise of misinformation underscores the need for scalable and reliable\nfact-checking solutions. Large language models (LLMs) hold promise in\nautomating fact verification, yet their effectiveness across global contexts\nremains uncertain. We systematically evaluate nine established LLMs across\nmultiple categories (open/closed-source, multiple sizes, diverse architectures,\nreasoning-based) using 5,000 claims previously assessed by 174 professional\nfact-checking organizations across 47 languages. Our methodology tests model\ngeneralizability on claims postdating training cutoffs and four prompting\nstrategies mirroring both citizen and professional fact-checker interactions,\nwith over 240,000 human annotations as ground truth. Findings reveal a\nconcerning pattern resembling the Dunning-Kruger effect: smaller, accessible\nmodels show high confidence despite lower accuracy, while larger models\ndemonstrate higher accuracy but lower confidence. This risks systemic bias in\ninformation verification, as resource-constrained organizations typically use\nsmaller models. Performance gaps are most pronounced for non-English languages\nand claims originating from the Global South, threatening to widen existing\ninformation inequalities. These results establish a multilingual benchmark for\nfuture research and provide an evidence base for policy aimed at ensuring\nequitable access to trustworthy, AI-assisted fact-checking.",
    "authors": [
      "Ihsan A. Qazi",
      "Zohaib Khan",
      "Abdullah Ghani",
      "Agha A. Raza",
      "Zafar A. Qazi",
      "Wassay Sajjad",
      "Ayesha Ali",
      "Asher Javaid",
      "Muhammad Abdullah Sohail",
      "Abdul H. Azeemi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2509.08803v1"
  },
  {
    "title": "Using machine learning to downscale coarse-resolution environmental variables for understanding the spatial frequency of convective storms",
    "summary": "Global climate models (GCMs), typically run at ~100-km resolution, capture\nlarge-scale environmental conditions but cannot resolve convection and cloud\nprocesses at kilometer scales. Convection-permitting models offer\nhigher-resolution simulations that explicitly simulate convection but are\ncomputationally expensive and impractical for large ensemble runs. This study\nexplores machine learning (ML) as a bridge between these approaches. We train\nsimple, pixel-based neural networks to predict convective storm frequency from\nenvironmental variables produced by a regional convection-permitting model. The\nML models achieve promising results, with structural similarity index measure\n(SSIM) values exceeding 0.8, capturing the diurnal cycle and orographic\nconvection without explicit temporal or spatial coordinates as input. Model\nperformance declines when fewer input features are used or specific regions are\nexcluded, underscoring the role of diverse physical mechanisms in convective\nactivity. These findings highlight ML potential as a computationally efficient\ntool for representing convection and as a means of scientific discovery,\noffering insights into convective processes. Unlike convolutional neural\nnetworks, which depend on spatial structure and grid size, the pixel-based\nmodel treats each grid point independently, enabling value-to-value prediction\nwithout spatial context. This design enhances adaptability to resolution\nchanges and supports generalization to unseen environmental regimes, making it\nparticularly suited for linking environmental conditions to convective features\nand for application across diverse model grids or climate scenarios.",
    "authors": [
      "Hungjui Yu",
      "Lander Ver Hoef",
      "Kristen L. Rasmussen",
      "Imme Ebert-Uphoff"
    ],
    "pdf_url": "http://arxiv.org/pdf/2509.08802v1"
  },
  {
    "title": "How to Reconfigure Your Alliances",
    "summary": "Different variations of alliances in graphs have been introduced into the\ngraph-theoretic literature about twenty years ago. More broadly speaking, they\ncan be interpreted as groups that collaborate to achieve a common goal, for\ninstance, defending themselves against possible attacks from outside. In this\npaper, we initiate the study of reconfiguring alliances. This means that, with\nthe understanding of having an interconnection map given by a graph, we look at\ntwo alliances of the same size~$k$ and investigate if there is a\nreconfiguration sequence (of length at most~$\\ell$) formed by alliances of size\n(at most)~$k$ that transfers one alliance into the other one. Here, we consider\ndifferent (now classical) movements of tokens: sliding, jumping,\naddition/removal. We link the latter two regimes by introducing the concept of\nreconfiguration monotonicity. Concerning classical complexity, most of these\nreconfiguration problems are \\textsf{PSPACE}-complete, although some are\nsolvable in \\textsf{Log\\-SPACE}. We also consider these reconfiguration\nquestions through the lense of parameterized algorithms and prove various\n\\textsf{FPT}-results, in particular concerning the combined parameter $k+\\ell$\nor neighborhood diversity together with $k$ or neighborhood diversity together\nwith $k$.",
    "authors": [
      "Henning Fernau",
      "Kevin Mann"
    ],
    "pdf_url": "http://arxiv.org/pdf/2509.08798v1"
  },
  {
    "title": "Distributed Unknown Input Observer Design with Relaxed Conditions: Theory and Application to Vehicle Platooning",
    "summary": "Designing observers for linear systems with both known and unknown inputs is\nan important problem in several research contexts, for example, fault diagnosis\nand fault-tolerant control, and cyber-secure control systems, and presents\nsignificant challenges in distributed state estimation due to the limited\nsensing capabilities of individual nodes. Existing methods typically impose an\nindividual input-to-output rank condition on each estimator node, which\nseverely restricts applicability in practical applications. This paper presents\na novel distributed unknown-input observer design scheme based on a geometric\napproach under much weaker assumptions than the ones available in the\nliterature. By leveraging the properties of the $(C, A)$-invariant (conditioned\ninvariant) subspace at each node, our methodology aims at reconstructing\nportions of the system state that remain unaffected by local unknown inputs,\nwhile integrating these estimates via a network-based information exchange. A\ncase study on vehicle platoon control shows the effectiveness of the proposed\napproach.",
    "authors": [
      "Ruixuan Zhao",
      "Guitao Yang",
      "Thomas Parisini",
      "Boli Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2509.08783v1"
  },
  {
    "title": "Extended Version: Security and Privacy Perceptions of Pakistani Facebook Matrimony Group Users",
    "summary": "In Pakistan, where dating apps are subject to censorship, Facebook matrimony\ngroups -- also referred to as marriage groups -- serve as alternative virtual\nspaces for members to search for potential life partners. To participate in\nthese groups, members often share sensitive personal information such as\nphotos, addresses, and phone numbers, which exposes them to risks such as\nfraud, blackmail, and identity theft. To better protect users of Facebook\nmatrimony groups, we need to understand aspects related to user safety, such as\nhow users perceive risks, what influences their trust in sharing personal\ninformation, and how they navigate security and privacy concerns when seeking\npotential partners online. In this study, through 23 semi-structured\ninterviews, we explore how Pakistani users of Facebook matrimony groups\nperceive and navigate risks of sharing personal information, and how cultural\nnorms and expectations influence their behavior in these groups.\n  We find elevated privacy concerns among participants, leading them to share\nlimited personal information and creating mistrust among potential partners.\nMany also expressed concerns about the authenticity of profiles and major\nsecurity risks, such as identity theft, harassment, and social judgment. Our\nwork highlights the challenges of safely navigating Facebook matrimony groups\nin Pakistan and offers recommendations for such as implementing stronger\nidentity verification by group admins, enforcing stricter cybersecurity laws,\nclear platform guidelines to ensure accountability, and technical feature\nenhancements -- including restricting screenshots, picture downloads, and\nimplementing anonymous chats -- to protect user data and build trust.",
    "authors": [
      "Mah Jan Dorazahi",
      "Deepthi Mungara",
      "Yasemin Acar",
      "Harshini Sri Ramulu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2509.08782v1"
  },
  {
    "title": "An End-to-End Deep Learning Framework for Arsenicosis Diagnosis Using Mobile-Captured Skin Images",
    "summary": "Background: Arsenicosis is a serious public health concern in South and\nSoutheast Asia, primarily caused by long-term consumption of\narsenic-contaminated water. Its early cutaneous manifestations are clinically\nsignificant but often underdiagnosed, particularly in rural areas with limited\naccess to dermatologists. Automated, image-based diagnostic solutions can\nsupport early detection and timely interventions.\n  Methods: In this study, we propose an end-to-end framework for arsenicosis\ndiagnosis using mobile phone-captured skin images. A dataset comprising 20\nclasses and over 11000 images of arsenic-induced and other dermatological\nconditions was curated. Multiple deep learning architectures, including\nconvolutional neural networks (CNNs) and Transformer-based models, were\nbenchmarked for arsenicosis detection. Model interpretability was integrated\nvia LIME and Grad-CAM, while deployment feasibility was demonstrated through a\nweb-based diagnostic tool.\n  Results: Transformer-based models significantly outperformed CNNs, with the\nSwin Transformer achieving the best results (86\\\\% accuracy). LIME and Grad-CAM\nvisualizations confirmed that the models attended to lesion-relevant regions,\nincreasing clinical transparency and aiding in error analysis. The framework\nalso demonstrated strong performance on external validation samples, confirming\nits ability to generalize beyond the curated dataset.\n  Conclusion: The proposed framework demonstrates the potential of deep\nlearning for non-invasive, accessible, and explainable diagnosis of arsenicosis\nfrom mobile-acquired images. By enabling reliable image-based screening, it can\nserve as a practical diagnostic aid in rural and resource-limited communities,\nwhere access to dermatologists is scarce, thereby supporting early detection\nand timely intervention.",
    "authors": [
      "Asif Newaz",
      "Asif Ur Rahman Adib",
      "Rajit Sahil",
      "Mashfique Mehzad"
    ],
    "pdf_url": "http://arxiv.org/pdf/2509.08780v1"
  },
  {
    "title": "CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization",
    "summary": "Massive MIMO systems rely on accurate Channel State Information (CSI)\nfeedback to enable high-gain beam-forming. However, the feedback overhead\nscales linearly with the number of antennas, presenting a major bottleneck.\nWhile recent deep learning methods have improved CSI compression, most overlook\nthe impact of quantization and entropy coding, limiting their practical\ndeployability. In this work, we propose an end-to-end CSI compression framework\nthat integrates a Spatial Correlation-Guided Attention Mechanism with\nquantization and entropy-aware training. Our model effectively exploits the\nspatial correlation among the antennas, thereby learning compact,\nentropy-optimized latent representations for efficient coding. This reduces the\nrequired feedback bitrates without sacrificing reconstruction accuracy, thereby\nyielding a superior rate-distortion trade-off. Experiments show that our method\nsurpasses existing end-to-end CSI compression schemes, exceeding benchmark\nperformance by an average of 21.5% on indoor datasets and 18.9% on outdoor\ndatasets. The proposed framework results in a practical and efficient CSI\nfeedback scheme.",
    "authors": [
      "Maryam Ansarifard",
      "Mostafa Rahmani",
      "Mohit K. Sharma",
      "Kishor C. Joshi",
      "George Exarchakos",
      "Alister Burr"
    ],
    "pdf_url": "http://arxiv.org/pdf/2509.08776v1"
  },
  {
    "title": "Optimization of geometric hypergraph embedding",
    "summary": "We consider the problem of embedding the nodes of a hypergraph into Euclidean\nspace under the assumption that the interactions arose through closeness to\nunknown hyperedge centres. In this way, we tackle the inverse problem\nassociated with the generation of geometric random hypergraphs. We propose two\nnew spectral algorithms; both of these exploit the connection between\nhypergraphs and bipartite graphs. The assumption of an underlying geometric\nstructure allows us to define a concrete measure of success that can be used to\noptimize the embedding via gradient descent. Synthetic tests show that this\napproach accurately reveals geometric structure that is planted in the data,\nand tests on real hypergraphs show that the approach is also useful for the\ndownstream tasks of detecting spurious or missing data and node clustering.",
    "authors": [
      "Francesco Zigliotto",
      "Desmond J. Higham"
    ],
    "pdf_url": "http://arxiv.org/pdf/2509.08772v1"
  },
  {
    "title": "Reconfigurable Holographic Surfaces and Near Field Communication for Non-Terrestrial Networks: Potential and Challenges",
    "summary": "To overcome the challenges of ultra-low latency, ubiquitous coverage, and\nsoaring data rates, this article presents a combined use of Near Field\nCommunication (NFC) and Reconfigurable Holographic Surfaces (RHS) for\nNon-Terrestrial Networks (NTN). A system architecture has been presented, which\nshows that the integration of RHS with NTN platforms such as satellites, High\nAltitute Platform Stations (HAPS), and Uncrewed Aerial Vehicles (UAV) can\nachieve precise beamforming and intelligent wavefront control in near-field\nregions, enhancing Energy Efficiency (EE), spectral utilization, and spatial\nresolution. Moreover, key applications, challenges, and future directions have\nbeen identified to fully adopt this integration. In addition, a use case\nanalysis has been presented to improve the EE of the system in a public safety\nuse case scenario, further strengthening the UAV-RHS fusion.",
    "authors": [
      "Muhammad Ali Jamshed",
      "Muhammad Ahmed Mohsin",
      "Hongliang Zhang",
      "Bushra Haq",
      "Aryan Kaushik",
      "Boya Di",
      "Weiwei Jiang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2509.08770v1"
  },
  {
    "title": "PCGBandit: One-shot acceleration of transient PDE solvers via online-learned preconditioners",
    "summary": "Data-driven acceleration of scientific computing workflows has been a\nhigh-profile aim of machine learning (ML) for science, with numerical\nsimulation of transient partial differential equations (PDEs) being one of the\nmain applications. The focus thus far has been on methods that require\nclassical simulations to train, which when combined with the data-hungriness\nand optimization challenges of neural networks has caused difficulties in\ndemonstrating a convincing advantage against strong classical baselines. We\nconsider an alternative paradigm in which the learner uses a classical solver's\nown data to accelerate it, enabling a one-shot speedup of the simulation.\nConcretely, since transient PDEs often require solving a sequence of related\nlinear systems, the feedback from repeated calls to a linear solver such as\npreconditioned conjugate gradient (PCG) can be used by a bandit algorithm to\nonline-learn an adaptive sequence of solver configurations (e.g.\npreconditioners). The method we develop, PCGBandit, is implemented directly on\ntop of the popular open source software OpenFOAM, which we use to show its\neffectiveness on a set of fluid and magnetohydrodynamics (MHD) problems.",
    "authors": [
      "Mikhail Khodak",
      "Min Ki Jung",
      "Brian Wynne",
      "Edmond chow",
      "Egemen Kolemen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2509.08765v1"
  },
  {
    "title": "Asymptotic structure. V. The coarse Menger conjecture in bounded path-width",
    "summary": "Menger's theorem tells us that if $S,T$ are sets of vertices in a graph $G$,\nthen (for $k\\ge0$) either there are $k+1$ vertex-disjoint paths between $S$ and\n$T$, or there is a set of $k$ vertices separating $S$ and $T$. But what if we\nwant the paths to be far apart, say at distance at least $c$? One might hope\nthat we can find either $k+1$ paths pairwise far apart, or $k$ sets of bounded\nradius that separate $S$ and $T$, where the bound on the radius is some $\\ell$\nthat depends only on $k,c$ (the ``coarse Menger conjecture''). We showed in an\nearlier paper that this is false for all $k\\ge 2$ and $c\\ge3$. To do so we gave\na sequence of finite graphs, counterexamples for larger and larger values of\n$\\ell$ with $k=2$, $c=3$. Our counterexamples contained subdivisions of uniform\nbinary trees with arbitrarily large depth as subgraphs.\n  Here we show that for any binary tree $T$, the coarse Menger conjecture is\ntrue for all graphs that contain no subdivision of $T$ as a subgraph, that is,\nit is true for graphs with bounded path-width (and, further, for graphs with\nbounded coarse path-width). This is perhaps surprising, since it is false for\nbounded tree-width.",
    "authors": [
      "Tung Nguyen",
      "Alex Scott",
      "Paul Seymour"
    ],
    "pdf_url": "http://arxiv.org/pdf/2509.08762v1"
  },
  {
    "title": "Fourier Learning Machines: Nonharmonic Fourier-Based Neural Networks for Scientific Machine Learning",
    "summary": "We introduce the Fourier Learning Machine (FLM), a neural network (NN)\narchitecture designed to represent a multidimensional nonharmonic Fourier\nseries. The FLM uses a simple feedforward structure with cosine activation\nfunctions to learn the frequencies, amplitudes, and phase shifts of the series\nas trainable parameters. This design allows the model to create a\nproblem-specific spectral basis adaptable to both periodic and nonperiodic\nfunctions. Unlike previous Fourier-inspired NN models, the FLM is the first\narchitecture able to represent a complete, separable Fourier basis in multiple\ndimensions using a standard Multilayer Perceptron-like architecture. A\none-to-one correspondence between the Fourier coefficients and amplitudes and\nphase-shifts is demonstrated, allowing for the translation between a full,\nseparable basis form and the cosine phase--shifted one. Additionally, we\nevaluate the performance of FLMs on several scientific computing problems,\nincluding benchmark Partial Differential Equations (PDEs) and a family of\nOptimal Control Problems (OCPs). Computational experiments show that the\nperformance of FLMs is comparable, and often superior, to that of established\narchitectures like SIREN and vanilla feedforward NNs.",
    "authors": [
      "Mominul Rubel",
      "Adam Meyers",
      "Gabriel Nicolosi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2509.08759v1"
  },
  {
    "title": "Learning Turbulent Flows with Generative Models: Super-resolution, Forecasting, and Sparse Flow Reconstruction",
    "summary": "Neural operators are promising surrogates for dynamical systems but when\ntrained with standard L2 losses they tend to oversmooth fine-scale turbulent\nstructures. Here, we show that combining operator learning with generative\nmodeling overcomes this limitation. We consider three practical turbulent-flow\nchallenges where conventional neural operators fail: spatio-temporal\nsuper-resolution, forecasting, and sparse flow reconstruction. For Schlieren\njet super-resolution, an adversarially trained neural operator (adv-NO) reduces\nthe energy-spectrum error by 15x while preserving sharp gradients at neural\noperator-like inference cost. For 3D homogeneous isotropic turbulence, adv-NO\ntrained on only 160 timesteps from a single trajectory forecasts accurately for\nfive eddy-turnover times and offers 114x wall-clock speed-up at inference than\nthe baseline diffusion-based forecasters, enabling near-real-time rollouts. For\nreconstructing cylinder wake flows from highly sparse Particle Tracking\nVelocimetry-like inputs, a conditional generative model infers full 3D velocity\nand pressure fields with correct phase alignment and statistics. These advances\nenable accurate reconstruction and forecasting at low compute cost, bringing\nnear-real-time analysis and control within reach in experimental and\ncomputational fluid mechanics. See our project page:\nhttps://vivekoommen.github.io/Gen4Turb/",
    "authors": [
      "Vivek Oommen",
      "Siavash Khodakarami",
      "Aniruddha Bora",
      "Zhicheng Wang",
      "George Em Karniadakis"
    ],
    "pdf_url": "http://arxiv.org/pdf/2509.08752v1"
  },
  {
    "title": "Design-GenNO: A Physics-Informed Generative Model with Neural Operators for Inverse Microstructure Design",
    "summary": "Inverse microstructure design plays a central role in materials discovery,\nyet remains challenging due to the complexity of structure-property linkages\nand the scarcity of labeled training data. We propose Design-GenNO, a\nphysics-informed generative neural operator framework that unifies generative\nmodeling with operator learning to address these challenges. In Design-GenNO,\nmicrostructures are encoded into a low-dimensional, well-structured latent\nspace, which serves as the generator for both reconstructing microstructures\nand predicting solution fields of governing PDEs. MultiONet-based decoders\nenable functional mappings from latent variables to both microstructures and\nfull PDE solution fields, allowing a multitude of design objectives to be\naddressed without retraining. A normalizing flow prior regularizes the latent\nspace, facilitating efficient sampling and robust gradient-based optimization.\nA distinctive feature of the framework is its physics-informed training\nstrategy: by embedding PDE residuals directly into the learning objective,\nDesign-GenNO significantly reduces reliance on labeled datasets and can even\noperate in a self-supervised setting. We validate the method on a suite of\ninverse design tasks in two-phase materials, including effective property\nmatching, recovery of microstructures from sparse field measurements, and\nmaximization of conductivity ratios. Across all tasks, Design-GenNO achieves\nhigh accuracy, generates diverse and physically meaningful designs, and\nconsistently outperforms the state-of-the-art method. Moreover, it demonstrates\nstrong extrapolation by producing microstructures with effective properties\nbeyond the training distribution. These results establish Design-GenNO as a\nrobust and general framework for physics-informed inverse design, offering a\npromising pathway toward accelerated materials discovery.",
    "authors": [
      "Yaohua Zang",
      "Phaedon-Stelios Koutsourelakis"
    ],
    "pdf_url": "http://arxiv.org/pdf/2509.08749v1"
  },
  {
    "title": "DEQuify your force field: More efficient simulations using deep equilibrium models",
    "summary": "Machine learning force fields show great promise in enabling more accurate\nmolecular dynamics simulations compared to manually derived ones. Much of the\nprogress in recent years was driven by exploiting prior knowledge about\nphysical systems, in particular symmetries under rotation, translation, and\nreflections. In this paper, we argue that there is another important piece of\nprior information that, thus fa,r hasn't been explored: Simulating a molecular\nsystem is necessarily continuous, and successive states are therefore extremely\nsimilar. Our contribution is to show that we can exploit this information by\nrecasting a state-of-the-art equivariant base model as a deep equilibrium\nmodel. This allows us to recycle intermediate neural network features from\nprevious time steps, enabling us to improve both accuracy and speed by\n$10\\%-20\\%$ on the MD17, MD22, and OC20 200k datasets, compared to the non-DEQ\nbase model. The training is also much more memory efficient, allowing us to\ntrain more expressive models on larger systems.",
    "authors": [
      "Andreas Burger",
      "Luca Thiede",
      "Al\u00e1n Aspuru-Guzik",
      "Nandita Vijaykumar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2509.08734v1"
  },
  {
    "title": "Data-driven generative simulation of SDEs using diffusion models",
    "summary": "This paper introduces a new approach to generating sample paths of unknown\nstochastic differential equations (SDEs) using diffusion models, a class of\ngenerative AI models commonly employed in image and video applications. Unlike\nthe traditional Monte Carlo methods for simulating SDEs, which require explicit\nspecifications of the drift and diffusion coefficients, our method takes a\nmodel-free, data-driven approach. Given a finite set of sample paths from an\nSDE, we utilize conditional diffusion models to generate new, synthetic paths\nof the same SDE. To demonstrate the effectiveness of our approach, we conduct a\nsimulation experiment to compare our method with alternative benchmark ones\nincluding neural SDEs. Furthermore, in an empirical study we leverage these\nsynthetically generated sample paths to enhance the performance of\nreinforcement learning algorithms for continuous-time mean-variance portfolio\nselection, hinting promising applications of diffusion models in financial\nanalysis and decision-making.",
    "authors": [
      "Xuefeng Gao",
      "Jiale Zha",
      "Xun Yu Zhou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2509.08731v1"
  },
  {
    "title": "Decentralized Stochastic Nonconvex Optimization under the Relaxed Smoothness",
    "summary": "This paper studies decentralized optimization problem\n$f(\\mathbf{x})=\\frac{1}{m}\\sum_{i=1}^m f_i(\\mathbf{x})$, where each local\nfunction has the form of $f_i(\\mathbf{x}) = {\\mathbb\nE}\\left[F(\\mathbf{x};{\\xi}_i)\\right]$ which is $(L_0,L_1)$-smooth but possibly\nnonconvex and the random variable ${\\xi}_i$ follows distribution ${\\mathcal\nD}_i$. We propose a novel algorithm called decentralized normalized stochastic\ngradient descent (DNSGD), which can achieve the $\\epsilon$-stationary point on\neach local agent. We present a new framework for analyzing decentralized\nfirst-order methods in the relaxed smooth setting, based on the Lyapunov\nfunction related to the product of the gradient norm and the consensus error.\nThe analysis shows upper bounds on sample complexity of ${\\mathcal\nO}(m^{-1}(L_f\\sigma^2\\Delta_f\\epsilon^{-4} + \\sigma^2\\epsilon^{-2} +\nL_f^{-2}L_1^3\\sigma^2\\Delta_f\\epsilon^{-1} + L_f^{-2}L_1^2\\sigma^2))$ per agent\nand communication complexity of $\\tilde{\\mathcal O}((L_f\\epsilon^{-2} +\nL_1\\epsilon^{-1})\\gamma^{-1/2}\\Delta_f)$, where $L_f=L_0 +L_1\\zeta$, $\\sigma^2$\nis the variance of the stochastic gradient, $\\Delta_f$ is the initial optimal\nfunction value gap, $\\gamma$ is the spectral gap of the network, and $\\zeta$ is\nthe degree of the gradient dissimilarity. In the special case of $L_1=0$, the\nabove results (nearly) match the lower bounds on decentralized nonconvex\noptimization in the standard smooth setting. We also conduct numerical\nexperiments to show the empirical superiority of our method.",
    "authors": [
      "Luo Luo",
      "Xue Cui",
      "Tingkai Jia",
      "Cheng Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2509.08726v1"
  },
  {
    "title": "Sharing is Caring: Efficient LM Post-Training with Collective RL Experience Sharing",
    "summary": "Post-training language models (LMs) with reinforcement learning (RL) can\nenhance their complex reasoning capabilities without supervised fine-tuning, as\ndemonstrated by DeepSeek-R1-Zero. However, effectively utilizing RL for LMs\nrequires significant parallelization to scale-up inference, which introduces\nnon-trivial technical challenges (e.g. latency, memory, and reliability)\nalongside ever-growing financial costs. We present Swarm sAmpling Policy\nOptimization (SAPO), a fully decentralized and asynchronous RL post-training\nalgorithm. SAPO is designed for decentralized networks of heterogenous compute\nnodes, where each node manages its own policy model(s) while \"sharing\" rollouts\nwith others in the network; no explicit assumptions about latency, model\nhomogeneity, or hardware are required and nodes can operate in silo if desired.\nAs a result, the algorithm avoids common bottlenecks in scaling RL\npost-training while also allowing (and even encouraging) new possibilities. By\nsampling rollouts \"shared\" across the network, it enables \"Aha moments\" to\npropagate, thereby bootstrapping the learning process. In this paper we show\nSAPO achieved cumulative reward gains of up to 94% in controlled experiments.\nWe also share insights from tests on a network with thousands of nodes\ncontributed by Gensyn community members running the algorithm on diverse\nhardware and models during an open-source demo.",
    "authors": [
      "Jeffrey Amico",
      "Gabriel Passamani Andrade",
      "John Donaghy",
      "Ben Fielding",
      "Tristin Forbus",
      "Harry Grieve",
      "Semih Kara",
      "Jari Kolehmainen",
      "Yihua Lou",
      "Christopher Nies",
      "Edward Phillip Flores Nu\u00f1o",
      "Diogo Ortega",
      "Shikhar Rastogi",
      "Austin Virts",
      "Matthew J. Wright"
    ],
    "pdf_url": "http://arxiv.org/pdf/2509.08721v1"
  }
]